---
title: 'Operating Systems'
date: 2020-04-15
permalink: /posts/2020/04/blog-post-20/
tags:
  - Note
---

This is my personal notes for Operating Systems.


线程和进程
-----------------
[参考博客](https://blog.csdn.net/justloveyou_/article/details/53448157)

* 简介  
并发与操作系统的生命历程息息相关。进程的出现，使得程序状态的保存变为现实，为进程间的切换提供了可能，实现了操作系统的并发，大大提高资源利用率。虽然进程的出现解决了操作系统的并发问题，但人们对实时性又有了更高的要求。由于一个进程由若干个子任务组成，所以人们就发明了线程，让每个线程负责一个独立的子任务，提高程序的响应灵敏度。一个进程虽然包括多个线程，但是这些线程是共同享有进程占有的资源和地址空间的。因此，虽然多线程提高了资源利用率，保证了实时性，但同时也带来了包括安全性、活跃性和性能等问题。总的来说，进程让操作系统的并发性成为可能，而线程让进程的内部并发成为可能。


* (1) 操作系统中为什么会出现进程？  

  说起进程的由来，我们需要从操作系统的发展历史谈起。    

  也许在今天，我们无法想象在很多年以前计算机是什么样子。我们现在可以用计算机来做很多事情：办公、娱乐、上网，但是在 计算机刚出现的时候，是为了解决数学计算的问题，因为很多大量的计算通过人力去完成是很耗时间和人力成本的。 在最初的时候，计算机只能接受一些特定的指令，用户输入一个指令，计算机就做一个操作。当用户在思考或者输入数据时，计算机就在等待。显然，这样效率会很低下，因为很多时候，计算机处于等待用户输入的状态。  

  那么，能不能把一系列需要操作的指令预先写下来，形成一个清单，然后一次性交给计算机，计算机不断地去读取指令来进行相应的操作？就这样， 批处理操作系统 诞生了。用户可以将需要执行的多个程序写在磁带上，然后交由计算机去读取并逐个地执行这些程序，并将输出结果写到另一个磁带上。  

  虽然批处理操作系统的诞生极大地提高了任务处理的便捷性，但是仍然存在一个很大的问题：  

  假如有两个任务 A 和 B，任务A 在执行到一半的过程中，需要读取大量的数据输入（I/O操作），而此时CPU只能静静地等待任务A读取完数据才能继续执行，这样就白白浪费了CPU资源。人们于是想，能否在 任务A 读取数据的过程中，让 任务B 去执行，当 任务A 读取完数据之后，让 任务B 暂停，然后让 任务A 继续执行？  

  但是这样就有一个问题，原来每次都是一个程序在计算机里面运行，也就说内存中始终只有一个程序的运行数据。而如果想要 任务A 执行 I/O操作 的时候，让 任务B 去执行，必然内存中要装入多个程序，那么如何处理呢？多个程序使用的数据如何进行辨别呢？并且，当一个程序运行暂停后，后面如何恢复到它之前执行的状态呢？  

  这个时候，人们就发明了进程，用进程来对应一个程序，每个进程对应一定的内存地址空间，并且只能使用它自己的内存空间，各个进程间互不干扰。并且，进程保存了程序每个时刻的运行状态，这样就为进程切换提供了可能。当进程暂停时，它会保存当前进程的状态（比如进程标识、进程的使用的资源等），在下一次重新切换回来时，便根据之前保存的状态进行恢复，然后继续执行。

  这就是并发，能够让操作系统从宏观上看起来同一个时间段有多个任务在执行。换句话说，进程让操作系统的并发成为了可能。注意，虽然并发从宏观上看有多个任务在执行，但是事实上，任一个具体的时刻，只有一个任务在占用CPU资源（当然是对于单核CPU来说的）。

* (2) 为什么会出现线程？  

  在出现了进程以后，操作系统的性能得到了大大的提升。虽然进程的出现解决了操作系统的并发问题，但是人们仍然不满足，人们逐渐对 实时性 有了要求。因为一个进程在一个时间段内只能做一件事情，如果一个进程有多个子任务，只能逐个地去执行这些子任务。比如，对于一个监控系统来说，它不仅要把图像数据显示在画面上，还要与服务端进行通信获取图像数据，还要处理人们的交互操作。如果某一个时刻该系统正在与服务器通信获取图像数据，而用户又在监控系统上点击了某个按钮，那么该系统就要等待获取完图像数据之后才能处理用户的操作，如果获取图像数据需要耗费 10s，那么用户就只有一直等待。显然，对于这样的系统，人们是无法满足的。  

  那么，可不可以将这些子任务分开执行呢？即，在系统获取图像数据的同时，如果用户点击了某个按钮，则会暂停获取图像数据，而先去响应用户的操作（因为用户的操作往往执行时间很短），在处理完用户操作之后，再继续获取图像数据。人们就发明了线程，让一个线程去执行一个子任务，这样一个进程就包括了多个线程，每个线程负责一个独立的子任务。这样，在用户点击按钮的时候，就可以暂停获取图像数据的线程，让 UI线程 响应用户的操作，响应完之后再切换回来，让获取图像的线程得到 CPU资源 。从而，让用户感觉系统是同时在做多件事情的，满足了用户对实时性的要求。  

  换句话说，进程让操作系统的并发性成为可能，而线程让进程的内部并发成为可能。但是要注意，一个进程虽然包括多个线程，但是这些线程是共同享有进程占有的资源和地址空间的。
  
  进程 是操作系统进行资源分配的基本单位，而 线程 是操作系统进行调度的基本单位。

* (3) 多线程并发

  由于多个线程是共同占有所属进程的资源和地址空间的，那么就会存在一个问题：如果多个线程要同时访问某个资源，怎么处理？ 这个问题就是并发安全性问题。  

  此外，可能有朋友会问，现在很多时候都采用多线程编程，那么是不是多线程的性能一定就由于单线程呢？答案是不一定，要看具体的任务以及计算机的配置。比如说：对于单核CPU，如果是 CPU密集型任务，如解压文件，多线程的性能反而不如单线程性能，因为解压文件需要一直占用 CPU资源，如果采用多线程，线程切换导致的开销反而会让性能下降。但是对于比如交互类型的任务，肯定是需要使用多线程的。而对于多核CPU，对于解压文件来说，多线程肯定优于单线程，因为多个线程能够更加充分利用每个核的资源。  

  虽然多线程能够提升程序性能，但是相对于单线程来说，它的编程要复杂地多，要考虑线程安全问题。因此，在实际编程过程中，要根据实际情况具体选择。


* (4) 并发历史

  早期的计算机不包含操作系统，它们从头到尾只执行一个程序，并且这个程序能够访问计算机中的所有资源。这对于昂贵且稀有的计算机资源来说是一种浪费；

  操作系统的出现使得计算机能同时运行多个程序，不同的程序都在单独的进程中运行，并且操作系统为各个独立执行的进程分配资源( eg: 通过粗粒度时间分片使程序共享资源，如 CPU 等 )。这无疑提高了计算机资源的利用率；

  在早期的分时系统中，每个进程的执行都是串行的。串行编程模型的优势在于其简单性和直观性，因为它每次只做一件事情，做完之后再做另一件。这种串行编程模型仍然存在着计算机资源利用率不高的问题；

  促使进程出现的因素同样也促使着线程的出现。线程允许在同一个进程中同时存在多个程序控制流。线程会共享进程范围内的资源，但每个线程都有各自的 程序计数器 、 栈 以及 局部变量 等等；

  线程也被成为**轻量级进程**。在大多数现代操作系统中，都是以线程为基本的调度单位，而不是进程。如果没有明确的协同机制，那么线程将彼此独立执行。由于同一个进程的所有线程都将共享进程的内存地址空间，因此这些线程都能访问相同的变量，这就需要实现一种比进程间共享数据粒度更细的数据共享机制。如果没有明确的同步机制来协同对共享数据的访问，将造成不可预测的结果。


-----------------------------------

进程有哪几种状态？
-------------

* 就绪状态(Ready)：进程已获得除处理机以外的所需资源，等待分配处理机(Scheduler)资源；

* 运行状态(Running)：占用处理机资源运行，处于此状态的进程数小于等于CPU数；

* 阻塞状态(Blocked)： 进程等待某种条件，在条件满足之前无法执行；

  Note: 还可能有PREEMPT(Block的一种)

  ![avatar](http://static.zybuluo.com/Rico123/xilfs88fqtduey2lj5o3503z/%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%B8%89%E7%A7%8D%E7%8A%B6%E6%80%81.jpg)


-----------------------------------

进程间的通信的几种方式
--------------------
* 管道（pipe）及命名管道（named pipe)  
  管道可用于具有亲缘关系的父子进程间的通信，命名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；

* 信号（signal)
  信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；

* 消息队列
  消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

* 共享内存
  可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等；

* 信号量
  主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段；

* 套接字
  这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。


-----------------------------------

线程有哪几种状态？
--------------------
在 Java虚拟机 中，线程从最初的创建到最终的消亡，要经历若干个状态：创建(new)、就绪(runnable/start)、运行(running)、阻塞(blocked)、等待(waiting)、时间等待(time waiting) 和 消亡(dead/terminated)。在给定的时间点上，一个线程只能处于一种状态，各状态的含义如下图所示：

  ![avatar](http://static.zybuluo.com/Rico123/ot7o6218591iwj9py999hs1u/%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.jpg)


-----------------------------------

线程同步的方式
-----------------------------------------
互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量

事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作


-----------------------------------

什么是死锁？死锁产生的条件？
-------------------------
* 1 死锁的概念

  在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。

* 2 死锁产生的四个必要条件  

  互斥：至少有一个资源必须属于非共享模式，即一次只能被一个进程使用；若其他申请使用该资源，那么申请进程必须等到该资源被释放为止；

  占有并等待：一个进程必须占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有；

  非抢占：进程不能被抢占，即资源只能被进程在完成任务后自愿释放

  循环等待：若干进程之间形成一种头尾相接的环形等待资源关系

* 3 死锁的处理基本策略和常用方法

  解决死锁的基本方法主要有 预防死锁、避免死锁、检测死锁、解除死锁、鸵鸟策略 等。

  * (1) 死锁预防  

    死锁预防的基本思想是 只要确保死锁发生的四个必要条件中至少有一个不成立，就能预防死锁的发生，具体方法包括：

    打破互斥条件: 允许进程同时访问某些资源。但是，有些资源是不能被多个进程所共享的，这是由资源本身属性所决定的，因此，这种办法通常并无实用价值。

    打破占有并等待条件：可以实行资源预先分配策略(进程在运行前一次性向系统申请它所需要的全部资源，若所需全部资源得不到满足，则不分配任何资源，此进程暂不运行；只有当系统能满足当前进程所需的全部资源时，才一次性将所申请资源全部分配给该线程)或者只允许进程在没有占用资源时才可以申请资源（一个进程可申请一些资源并使用它们，但是在当前进程申请更多资源之前，它必须全部释放当前所占有的资源）。但是这种策略也存在一些缺点：在很多情况下，无法预知一个进程执行前所需的全部资源，因为进程是动态执行的，不可预知的；同时，会降低资源利用率，导致降低了进程的并发性。

    打破非抢占条件：允许进程强行从占有者那里夺取某些资源。也就是说，如果一个进程占有了一部分资源，在其申请新的资源且得不到满足时，它必须释放所有占有的资源以便让其它线程使用。这种预防死锁的方式实现起来困难，会降低系统性能。

    打破循环等待条件：实行资源有序分配策略。对所有资源排序编号，所有进程对资源的请求必须严格按资源序号递增的顺序提出，即只有占用了小号资源才能申请大号资源，这样就不回产生环路，预防死锁的发生。

  * (2) 死锁避免的基本思想  
    
    死锁避免的基本思想是动态地检测资源分配状态，以确保循环等待条件不成立，从而确保系统处于安全状态。所谓安全状态是指：如果系统能按某个顺序为每个进程分配资源（不超过其最大值），那么系统状态是安全的，换句话说就是，如果存在一个安全序列，那么系统处于安全状态。资源分配图算法和银行家算法是两种经典的死锁避免的算法，其可以确保系统始终处于安全状态。其中，资源分配图算法应用场景为每种资源类型只有一个实例(申请边，分配边，需求边，不形成环才允许分配)，而银行家算法应用于每种资源类型可以有多个实例的场景。


  * (3) 死锁解除

    死锁解除的常用两种方法为**进程终止**和**资源抢占**。  
    所谓进程终止是指简单地终止一个或多个进程以打破循环等待，包括两种方式：终止所有死锁进程和一次只终止一个进程直到取消死锁循环为止；所谓资源抢占是指从一个或多个死锁进程那里抢占一个或多个资源，此时必须考虑三个问题：  

    (I). 选择一个牺牲品  
    (II). 回滚：回滚到安全状态  
    (III). 饥饿（在代价因素中加上回滚次数，回滚的越多则越不可能继续被作为牺牲品，避免一个进程总是被回滚）

-----------------------------------

内存管理中的page和segment的区别
-------------------------
* segment  

  段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

* page

  页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。

* 不同点  

  (1) 目的不同：分page是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分segment的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息；

  (2) 大小不同：page的大小固定且由系统决定，而segment的长度却不固定，由其所完成的功能决定；

  (3) 地址空间不同：segment向用户提供二维地址空间；page向用户提供的是一维地址空间；

  (4) 信息共享：segment是信息的逻辑单位，便于存储保护和信息的共享，page的保护和共享受到限制；

  (5) 内存碎片：page式存储管理的优点是没有外碎片（因为page的大小固定），但会产生内碎片（一个page可能填充不满）；而segment式管理的优点是没有内碎片（因为segment大小可变，改变段大小来消除内碎片）。但segment换入换出时，会产生外碎片（比如4k的segment插入5k的内存片段，会产生1k的外碎片）。


-----------------------------------

操作系统中进程调度策略有哪几种？
-------------------------
* FCFS  
  first come, first served

* LCFS  
  last come, first served

* SRTF  
  根据process的remainTime, 先执行remainTime最小的process

* RR (RoundRobin)  
  在FCFS的基础上加上quantum参数, process的每次的CPU执行时间不超过quantum, 超过则转PREEMPT状态

* PRIO (PriorityScheduler)  
  设置一个activeQ, 一个expiredQ, 每次从activeQ中取dynamic prio最高的process, 当prio变为-1时, 将process的prio重置为static prio并放入expiredQ， 如果activeQ空了, 交换expiredQ和activeQ

* PREemptive PRIO (PREPRIO)  
  和PRIO相同, 不同的是prio高的process可以有PREEMPT当前正在运行的process

-----------------------------------

虚拟内存(virtual memory)和paging
-----------------

* 虚拟内存:  
  virtual memory对应于main memory (physical memory), 是secondary memory中的一部分, 用来存储process. 

  process通过pageTable把每个page和main memory中的frame对应起来, 即logic adress (page number + instruction offset) -> phsical adress (frame number + instruction offset)

  需要操作某个page时, 将logic adress中的page number取出来，通过pageTable转换为frame number, 加上instruction offset, 得到physical adress. 

  如果某个page不在frame中, 即触发page Fault。如果frame已满, 则需要进行page replacement.

  ![avatar](https://img-blog.csdn.net/20171021161259614?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanVzdGxvdmV5b3Vf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


* 页面置换算法(page replacement)

  * FIFO:  
  从main memory中从上到下依次选取frame进行置换, 每个frame机会均等

  * Random:  
  随机选取

  * Clock:   
  每次需要置换时, 选取第一个reference bit为0的frame, 并将遍历过的frame的reference bit置为0，表示从下一周期重新计算

  * NRU(Not recently used):  
  frames被划分成4个等级, 应该选取等级最低的:  
  3 referenced, modified  
  2 referenced, not modified  
  1 not referenced, modified  
  0 not referenced, not modified  
  遍历main memory, 随机选取等级最低的集合中的1个  
  同时, 操作系统会在固定的时间间隔后清空所有的(frame中page的)referenced bit, 从下一周期开始重新计算  

  * Aging:  
  给每个frame赋予一个age, 每次置换时更新所有frame的age, reference 0/1加到最左边一位, 并选取age最小的frame换出去  
  同时清空所有的referenced bit, 从下一周期开始重新计算   
  if a page has referenced bits 1,0,0,1,1,0 in the past 6 clock ticks, its referenced counter will look like this: 10000000, 01000000, 00100000, 10010000, 11001000, 01100100.

  * WorkingSet:  
  找到reference bit 为0, 且上一次被map的时间(tau)距离当前时间>delta的frame, 如果没有大于delta的, 选择tau最小(时间最早)的ref = 0的frame, 如果仍然没有, 选择tau最小(时间最早)的ref = 1的frame


* 虚拟内存的应用与优点

  虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。虚拟内存的使用可以带来以下好处：

  * 1 在内存中可以保留多个进程，系统并发度提高

  * 2 解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大


-----------------------------------

颠簸
-----------------------------------

颠簸本质上是指频繁的页调度行为，具体来讲，进程发生page fault，这时，必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此，会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸（抖动）。

内存颠簸的解决策略包括：

* 1 如果是因为页面替换策略失误，可以修改替换算法来解决这个问题；

* 2 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量；

* 否则，还剩下两个办法：终止该进程或增加物理内存容量。
