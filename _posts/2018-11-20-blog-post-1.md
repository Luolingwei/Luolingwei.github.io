---
title: 'Pandas'
date: 2018-11-20
permalink: /posts/2019/07/blog-post-1/
tags:
  - Note
---

This is my personal notes for pandas.  


Introduction
------
pandas是python中十分实用的数据分析包，支持各种增删改查，groupby等操作，其主要的数据形式是DataFrame和Series，下面对其核心操作进行介绍  



实例展示
------
1 生成df  

生成df的方式有多种，下面介绍4种常用的方式  

```python
    # 1 list字典生成df  外面的key作为列索引
    data = {'水果':['苹果','梨','草莓'],
       '数量':[3,2,5],
       '价格':[10,9,8]}
    df = DataFrame(data)

    # 2 嵌套字典生成df  外面的key作为列索引，里面的key作为行索引
    data = {'数量':{'苹果':3,'梨':2,'草莓':5},
       '价格':{'苹果':10,'梨':9,'草莓':8}}
    df = DataFrame(data)

    # 3 Series字典生成df  和list类似
    data = {'水果':Series(['苹果','梨','草莓']),
       '数量':Series([3,2,5]),
       '价格':Series([10,9,8])}
    df = DataFrame(data)

    # 4 先生成df的index，然后一列一列的添加，列长度要与索引长度相同

    # 生成前一周的日期索引
    raw=pd.DataFrame(index=pd.date_range(start=datetime.date.strftime(datetime.date.today()-datetime.timedelta(days=8),"%Y-%m-%d"),end=datetime.date.strftime(datetime.date.today()-datetime.timedelta(days=1),"%Y-%m-%d"),freq='D'))

    # 以list形式添加列
    raw['lidCount']=lidCount
    raw['sidCount']=sidCount
    raw['lidCount_online']=lidCount_online
    raw['sidCount_online']=sidCount_online
    raw['lidCount_rate']=lidCount_rate
    raw['sidCount_rate']=sidCount_rate


```  

2 df切片  

对df进行选取，主要有loc,iloc,ix等方式, loc是根据行名列明进行索引，而iloc是根据行号和列号索引  

```python

        # 假设有如下df
        #    A  B  C
        # 0  1  4  7
        # 1  2  5  8
        # 2  3  6  9

        # 选取B列和C列
        df.loc[:,['B','C']]
        df.loc[['B','C']]
        
        # 选取第2列和第3列
        df.iloc[:,1:3]
        df.iloc[:[1,2]]

        # 选取0行和第1行
        df.iloc[0:2,:]
        df.iloc[[0,1],:]

```

3 df清洗  

df清洗主要包括处理空值和重复值，常用的有dropna(),fillna(),drop_duplicates()函数  

```python

        # 假设有如下df
        #     A    B    C
        # 0  1.0  NaN  3.0
        # 1  NaN  NaN  2.0
        # 2  NaN  NaN  NaN
        # 3  8.0  NaN  NaN


        # 去除空值 非inplace操作
        df=df.dropna() #去除所有包含空值的行
        df=df.dropna(axis=1) #去除所有包含空值的列
        df=df.dropna(how='all') #去除全部为空值的行

        # 填充空值
        DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
        df.fillna(0) #将NAN值转换为0
        df.fillna(method='ffill') #用前面的值填充空值
        df.fillna(method='backfill') #用后面的值填充空值

        values = {'A': 0, 'B': 1, 'C': 2}
        df.fillna(value=values) #ABC列分别填充不同的值

        # 去除重复行
        df.drop_duplicates(subset=['A','B'],keep='first') #去除A和B列都相同的行, 并保留第一个记录
        df.drop_duplicates(subset=None,keep=None) #所有都相同的删除，并且不保留


```

4 df排序  

df排序主要包括按value排序和按index排序，分别对应sort_values()和sort_index()两种方法  

```python


        # 假设有如下df
        #    C  B  C
        # 0  8  4  9
        # 1  2  4  8
        # 2  5  6  7

        df.sort_values(by=['A','B'],ascending=False) #以AB列排序，A列相同的按B列
        df.sort_values(by=['A'],na_position='first') #以A列排序，A列为空的放到前面
        df.sort_index(axis=0,ascending=False) #按行索引降序排列
        df.sort_index(axis=1) #按列索引升序排列

```

5 df合并  

df合并主要有join,concat,merge三种方法  

```python

        # 假设有如下df(A) df(B)

        #    A  B  C           #    a  b   c   d
        # 0  1  4  7           # 0  1  5   3   8
        # 1  2  5  8           # 1  2  7  10   8
        # 2  3  6  9           # 2  3  2  45  43

        
        # 1 concat, 拼接 (根据index)

        pd.concat([A,B],axis=1) #横着进行拼接，以行索引进行匹配

        #    A  B  C  a  b   c   d
        # 0  1  4  7  1  5   3   8
        # 1  2  5  8  2  7  10   8
        # 2  3  6  9  3  2  45  43

        pd.concat([A,B],axis=0) #竖着着进行拼接，以列索引进行匹配

        #      A    B    C    a    b     c     d
        # 0  1.0  4.0  7.0  NaN  NaN   NaN   NaN
        # 1  2.0  5.0  8.0  NaN  NaN   NaN   NaN
        # 2  3.0  6.0  9.0  NaN  NaN   NaN   NaN
        # 0  NaN  NaN  NaN  1.0  5.0   3.0   8.0
        # 1  NaN  NaN  NaN  2.0  7.0  10.0   8.0
        # 2  NaN  NaN  NaN  3.0  2.0  45.0  43.0


        # 2 join, 连接 (根据index)

        A.join(B) #默认以index进行匹配 默认left join

        #    A  B  C  a  b   c   d
        # 0  1  4  7  1  5   3   8
        # 1  2  5  8  2  7  10   8
        # 2  3  6  9  3  2  45  43

        A.set_index('A').join(B,how='inner') #因为A换了index,只匹配上了1,2两个index，因为是inner方法，其他数据被丢弃

        #    B  C  a  b   c   d
        # 1  4  7  2  7  10   8
        # 2  5  8  3  2  45  43


        # 3 merge 合并 (根据某列)
        B['A']= [1,2,3] #增加和A相同的一列,merge之后只剩下一个
        pd.merge(A,B,on='A')

        #    A  B  C  a  b   c   d
        # 0  1  4  7  1  5   3   8
        # 1  2  5  8  2  7  10   8
        # 2  3  6  9  3  2  45  43


```

6 groupby  

df的groupby函数可以按某字段聚合然后计算每个group的特征，返回新的df  

```python

  # 下面的函数将df按groupid聚合，并计算每个group的相应指标，得到的结果是每个group的这3个指标

  def func(group):
      return pd.Series({
          'DAU': group['UV'].mean(),
          'maxUV': max(group['UV']),
          'minUV': min(group['UV'])
      })

  df_summary = df_joined.groupby(groupid).apply(func)

```

7 日期转换函数  

df日期和周转换函数示例  

```python

      # 周二开始的周
      pd.DatetimeIndex(['2019-07-17','2019-07-18']).to_period(pd.tseries.offsets.Week(weekday=0))

      # 输出
      PeriodIndex(['2019-07-16/2019-07-22', '2019-07-16/2019-07-22'], dtype='period[W-MON]', freq='W-MON')


      # 周三开始的周
      pd.DatetimeIndex(['2019-07-17','2019-07-18']).to_period(pd.tseries.offsets.Week(weekday=1)) # 周三开始的周

      # 输出
      PeriodIndex(['2019-07-17/2019-07-23', '2019-07-17/2019-07-23'], dtype='period[W-TUE]', freq='W-TUE')

```
